apiVersion: v1
data:
  alerting.rules: |
    groups:
    - name: etcd.rules
      rules:
      #### Etcd Alerting rules
      - alert: etcdDown
        expr: absent(up{job="etcd"} == 1)
        for: 5m
        labels:
          severity: Disaster
          sendto: Zabbix
          component: Infrastructure
        annotations:
          message: 'etcd member {{$labels.instance}} is Down or Unreachable'
      - alert: etcdInsufficientMembers
        expr: count(up{job="etcd"} == 0) > (count(up{job="etcd"}) / 2 - 1)
        for: 5m
        labels:
          severity: Disaster
          sendto: Zabbix
          component: Infrastructure
        annotations:
          message: 'Insufficent etcd members.etcd cluster unstable'
      - alert: etcdNoLeader
        expr: etcd_server_has_leader{job="etcd"} == 0
        for: 5m
        labels:
          severity: Disaster
          sendto: Zabbix
          component: Infrastructure
        annotations:
          message: 'etcd member {{ $labels.instance }} has no leader'
  application.rules: |
    groups:
    - name: application.rules
      rules:
      - alert: quotaExceeded
        expr: 100 * kube_resourcequota{type="used"} / ignoring(instance, job, type) kube_resourcequota{type="hard"} > 90
        for: 1h
        labels:
          severity: High
        annotations:
          message: '{{printf "%0.0f" $value}}% usage of {{$labels.resource}} in namespace {{$labels.namespace}}'
      - alert: deploymentMismatchGeneration
        expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'Deployment {{$labels.namespace}}/{{$labels.deployment}} generation mismatch'
      - alert: deploymentMismatchReplicas
        expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'Deployment {{$labels.namespace}}/{{$labels.deployment}} replica mismatch'
      - alert: statefulsetMismatchReplicas
        expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'StatefulSet {{$labels.namespace}}/{{$labels.statefulset}} replica mismatch'
      - alert: statefulsetMismatchGeneration
        expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'StatefulSet {{$labels.namespace}}/{{$labels.statefulset}} generation mismatch'
      - alert: daemonsetRolloutStuck
        expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'Only {{$value}}% of desired pods scheduled and ready for daemon set {{$labels.namespace}}/{{$labels.daemonset}}'
      - alert: daemonsetNotScheduled
        expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}} are not scheduled'
      - alert: daemonsetMisScheduled
        expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'A number of pods of daemonset {{$labels.namespace}}/{{$labels.daemonset}} are running where they are not supposed to run'
  deadman-switch.rules: |
    groups:
    - name: deadman-switch.rules
      rules:
      - alert: deadman
        expr: vector(1)
        for: 1h
        labels:
          severity: Information
        annotations:
          message: Dummy Check
          summary: This is a dummy check meant to ensure that the entire Alerting pipeline is functional.
  etcd.rules: |
    groups:
    - name: etcd.rules
      rules:
      - alert: etcdDown
        expr: absent(up{job="etcd"} == 1)
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: 'etcd member {{$labels.instance}} is Down or Unreachable'
      - alert: etcdInsufficientMembers
        expr: count(up{job="etcd"} == 0) > (count(up{job="etcd"}) / 2 - 1)
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: 'Insufficent etcd members.etcd cluster unstable'
      - alert: etcdNoLeader
        expr: etcd_server_has_leader{job="etcd"} == 0
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: 'etcd member {{ $labels.instance }} has no leader'
      - alert: etcd_HighNumberOfLeaderChanges
        expr: increase(etcd_server_leader_changes_seen_total{job="etcd"}[1h]) > 3
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'etcd instance {{ $labels.instance }} has seen {{$value|printf "%.1f"}} leader changes within the last hour'
      - alert: etcd_HighNumberOfFailedProposals
        expr: increase(etcd_server_proposals_failed_total{job="etcd"}[1h]) > 3
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'etcd instance {{ $labels.instance }} has seen {{$value | printf "%.2f"}} proposal failures within the last hour'
      - alert: etcd_HighFsyncDurations
        expr: histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket[5m])) > 0.5
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'etcd instance {{ $labels.instance }} fsync durations are high'
      - alert: etcd_HighCommitDurations
        expr: histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket[5m])) > 0.25
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'etcd instance {{ $labels.instance }} commit durations are high: {{$value | printf "%.2f"}}sec'
  host.rules: |
    groups:
    - name: host.rules
      rules:
      - alert: node_cpu
        expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100) > 75
        for: 1h
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}}: CPU usage is above 75% (current value is: {{$value|printf "%.1f"}}%)'
          summary: '{{$labels.instance}} CPU usage is above 75%'
      - alert: node_cpu
        expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100) > 85
        for: 1h
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}}: CPU usage is above 85% (current value is: {{$value|printf "%.1f"}}%)'
          summary: 'CPU usage is above 85% in the referred host'
      - alert: node_disk_use
        expr: sort(node_filesystem_free_bytes{device!="ramfs",fstype="ext4"} / node_filesystem_size_bytes{device!="ramfs",fstype="ext4"} * 100) < 15
        for: 5m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} device {{$labels.device}} on {{$labels.mountpoint}} got less than 15% space left ({{$value|printf "%.1f"}}%).'
          summary: '{{$labels.instance}}: Filesystem is running out of space soon.'
      - alert: node_disk_use
        expr: sort(node_filesystem_free_bytes{device!="ramfs",fstype="ext4"} / node_filesystem_size_bytes{device!="ramfs",fstype="ext4"} * 100) < 5
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}} device {{$labels.device}} on {{$labels.mountpoint}} got less than 5% space left ({{$value|printf "%.1f"}}%).'
          summary: '{{$labels.instance}}: Filesystem is running out of space soon.'
      - alert: node_disk_full
        expr: predict_linear(node_filesystem_free_bytes{mountpoint!~"^/etc/(?:resolv.conf|hosts|hostname)$",fstype!="tmpfs"}[6h], 3600 * 24) < 0 and on(instance) up
        for: 30m
        labels:
          severity: Disaster
        annotations:
          message: 'Device {{$labels.device}} on node {{$labels.instance}} is running full within the next 24 hours (mounted at {{$labels.mountpoint}})'
          summary: 'Node disk is running full within 24 hours'
      - alert: node_disk_full
        expr: predict_linear(node_filesystem_free_bytes{mountpoint!~"^/etc/(?:resolv.conf|hosts|hostname)$",fstype!="tmpfs"}[6h], 3600 * 2) < 0 and on(instance) up
        for: 10m
        labels:
          severity: Disaster
        annotations:
          message: 'Device {{$labels.device}} on node {{$labels.instance}} is running full within the next 2 hours (mounted at {{$labels.mountpoint}})'
          summary: 'Node disk is running full within 2 hours'
      - alert: node_disk_read
        expr: (rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m])) > 10
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.device}} has a high read latency of {{$value|printf "%.1f"}}%'
          summary: 'High read latency observed for device {{ $labels.device }}'
      - alert: node_disk_write
        expr: (rate(node_disk_write_time_seconds_total[5m]) / rate(node_disk_writes_completed_total[5m])) > 10
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.device}} has a high write latency of {{$value|printf "%.1f"}}%'
          summary: 'High write latency observed for device {{ $labels.device }}'
      - alert: node_memory_use
        expr: ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) /  node_memory_MemTotal_bytes) * 100 < 10
        for: 1h
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}} is using at least 90% memory ({{$value|printf "%.1f"}}%)'
          summary: '{{$labels.instance}}: Using lots of RAM.'
      - alert: node_memory_swap
        expr: (node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) < (node_memory_SwapTotal_bytes * 0.4)
        for: 1m
        labels:
          severity: High
        annotations:
          message: 'Host {{$labels.instance}} has a high swap usage of {{$value|printf "%.1f"}}%}.'
          summary: 'Server has a high swap usage'
      - alert: node_memory_paging
        expr: avg(irate(node_vmstat_pgpgin[5m])) by (instance) > 80
        for: 5m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} has a memory paging rate of change higher than 80%: {{$value|printf "%.1f"}}%'
          summary: '{{$labels.instance}}: memory paging rate is high: {{$value|printf "%.1f"}}%'
      - alert: node_cpu_load1
        expr: sum(rate(node_load1[5m])) by (instance) >= 3
        for: 30m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}}: Running on high cpuload1: {{$value|printf "%.1f"}}%'
          summary: '{{$labels.instance}} is running with cpuload1: {{$value|printf "%.1f"}}%'
      - alert: node_cpu_load15
        expr: sum(rate(node_load15[5m])) by (instance) >= 1
        for: 10m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}}: Running on high cpuload15: {{$value|printf "%.1f"}}%'
          summary: '{{$labels.instance}} is running with cpuload15: {{$value|printf "%.1f"}}%'
      - alert: node_cpu_util
        expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100) >= 90
        for: 1h
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}} has total CPU utilization over 90% for at least 1h: {{$value|printf "%.1f"}}%'
          summary: '{{$labels.instance}}: High CPU utilization.'
      - alert: node_entropy
        expr: node_entropy_available_bits < 300
        for: 1d
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} has available entropy bits of {{ $value }}'
          summary: '{{$labels.instance}}: is low on entropy bits.'
      - alert: node_network_conntrack
        expr: sort(node_nf_conntrack_entries > node_nf_conntrack_entries_limit * 0.8)
        for: 5m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} has network Connection Tracking System entries of {{$value|printf "%.1f"}} connections.'
          summary: '{{$labels.instance}}: available network conntrack entries are low.'
      - alert: node_network_drop_receive
        expr: delta(node_network_receive_drop_total{device!="lo"}[1m]) >= 5
        for: 30s
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high drop in network reception: ({{$value|printf "%.1f"}} packets).'
          summary: '{{$labels.instance}} host has a high receive drop'
      - alert: node_network_drop_send
        expr: delta(node_network_transmit_drop_total{device!="lo"}[1m]) >= 5
        for: 30s
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high drop in network transmission: ({{$value|printf "%.1f"}} packets)'
          summary: '{{$labels.instance}} host has a high transmit drop'
      - alert: node_network_error_receive
        expr: delta(node_network_receive_errs_total{device!="lo"}[1m]) >= 3
        for: 30s
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high error rate in network reception: ({{$value|printf "%.1f"}} packets)'
          summary: '{{$labels.instance}} host has unusual high reception errors'
      - alert: node_network_error_send
        expr: delta(node_network_transmit_errs_total{device!="lo"}[1m]) >= 3
        for: 30s
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high error rate in network transmission: ({{$value|printf "%.1f"}} packets)'
          summary: '{{$labels.instance}} host has unusual high transmission errors'
      - alert: node_cpu_limit_overcommit
        expr: (sum(kube_pod_container_resource_limits{resource="cpu"}) by (node) / sum(kube_node_status_capacity_cpu_cores) by (node))*100 >= 100
        for: 1h
        labels:
          severity: High
        annotations:
          message: 'Host {{$labels.node}} has an overcommited CPU limit of {{$value|printf "%.1f"}}%'
      - alert: node_memory_limit_overcommit
        expr: (sum(kube_pod_container_resource_limits{resource="memory"}) by (node) / sum(kube_node_status_capacity_memory_bytes) by (node))*100 >= 100
        for: 1h
        labels:
          severity: High
        annotations:
          message: 'Host {{$labels.node}} has an overcommited memory limit of {{$value|printf "%.1f"}}%'
      - alert: node_cpu_request_overcommit
        expr: (sum(kube_pod_container_resource_requests_cpu_cores) by (node) / sum(kube_node_status_capacity_cpu_cores) by (node))*100 >= 100
        for: 1h
        labels:
          severity: Disaster
        annotations:
          message: 'Host {{$labels.node}} has an overcommited CPU request of {{$value}}%'
      - alert: node_memory_request_overcommit
        expr: (sum(kube_pod_container_resource_requests_memory_bytes) by (node) / sum(kube_node_status_capacity_memory_bytes) by (node))*100 >= 100
        for: 1h
        labels:
          severity: Disaster
        annotations:
          message: 'Host {{$labels.node}} has an overcommited memory request of {{$value|printf "%.1f"}}%'
  job.rules: |
    groups:
    - name: job.rules
      rules:
      - alert: cronjob_Running
        expr: time() - kube_cronjob_next_schedule_time > 3600
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'CronJob {{$labels.namespace}}/{{$labels.cronjob}} is taking more than 1h to complete.'
      - alert: job_Completion
        expr: kube_job_spec_completions - kube_job_status_succeeded > 0
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Job {{$labels.namespace}}/{{$labels.job_name}} is taking more than 1h to complete.'
      - alert: job_Failed
        expr: kube_job_status_failed > 0
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Job {{$labels.namespace}}/{{$labels.job_name}} failed to complete.'
  kubernetes.rules: |
    groups:
    - name: kubernetes.rules
      rules:
      - alert: KubeletUp
        expr: time() - container_last_seen{id="/system.slice/kubelet.service",id="/system.slice/kubelet.service"} > 60
        for: 5s
        labels:
          severity: Disaster
        annotations:
          message: 'Kubelet host process is unstable on node {{$labels.instance}}'
      - alert: KubeSystemStatus
        expr: rate(kube_pod_container_status_restarts_total{namespace="kube-system"}[1h]) * 3600 > 60
        for: 5s
        labels:
          severity: Disaster
        annotations:
          message: 'Container {{$labels.container_name}} is restarting. {{$labels.namespace}}/{{$labels.pod}} is not ready or CrashLooping'
      - alert: KubeApiReqLatency
        expr: histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="kubernetes-apiservers",verb!~"^(?:WATCH|WATCHLIST|PROXY|CONNECT)$"}[5m])) without(instance, pod)) / 1e+06 > 3
        for: 5m
        labels:
          severity: High
        annotations:
          message: 'Kubernetes Apiserver has a latency of {{$value|printf "%.1f"}} seconds for {{$labels.verb}} {{$labels.resource}}.'
      - alert: KubeApiReqLatency
        expr: histogram_quantile(0.99, sum(rate(apiserver_request_latencies_bucket{job="kubernetes-apiservers",verb!~"^(?:WATCH|WATCHLIST|PROXY|CONNECT)$"}[5m])) without(instance, pod)) / 1e+06 > 5
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: 'Kubernetes Apiserver has a latency of {{$value|printf "%.1f"}} seconds for {{$labels.verb}} {{$labels.resource}}'
      - alert: KubeApiReqError
        expr: sum(rate(apiserver_request_count{job="kubernetes-apiservers",code=~"^(?:5..)$"}[5m])) without(instance, pod) / sum(rate(apiserver_request_count{job="kubernetes-apiservers"}[5m])) without(instance, pod) * 100 > 5
        for: 5m
        labels:
          severity: Disaster
        annotations:
          message: 'Kubernetes Apiserver is erroring for {{$value|printf "%.1f"}}% of requests (>5%)'
      - alert: KubeApiClientError
        expr: sum(rate(rest_client_requests_total{code!~"2.."}[1h])) by (instance, job) * 100 / sum(rate(rest_client_requests_total[1h])) by (instance, job) > 4
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Kubernetes Apiserver client {{ $labels.job }}/{{ $labels.instance}} is experiencing {{$value|printf "%.1f"}}% errors'
  node.rules: |
    groups:
    - name: host.rules
      rules:
      #### Host Alerting Rules
      - alert: nodeReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 15s
        labels:
          severity: Disaster
        annotations:
          message: 'Host {{$labels.instance}} has been unready with this condition: {{$labels.condition}}'
      - alert: nodeCpu
        expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[1h])) by (instance) * 100) > 75
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}}: CPU usage is above 75% (current value is: {{$value|printf "%.1f"}}%)'
      - alert: nodeDisk
        expr: sort(node_filesystem_free_bytes{device!="ramfs",fstype="ext4"} / node_filesystem_size_bytes{device!="ramfs",fstype="ext4"} * 100) < 15
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} device {{$labels.device}} on {{$labels.mountpoint}} got less than 15% space left ({{$value|printf "%.1f"}}%).'
      - alert: nodeDisk
        expr: sort(node_filesystem_free_bytes{device!="ramfs",fstype="ext4"} / node_filesystem_size_bytes{device!="ramfs",fstype="ext4"} * 100) < 5
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.instance}} device {{$labels.device}} on {{$labels.mountpoint}} got less than 5% space left ({{$value|printf "%.1f"}}%).'
      - alert: nodeMemory
        expr: ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) /  node_memory_MemTotal_bytes) * 100 < 10
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} is using at least 90% memory ({{$value|printf "%.1f"}}%)'
      - alert: nodeEntropy
        expr: node_entropy_available_bits < 300
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} has available entropy bits of {{ $value }}'
      - alert: nodeNetworkConntrack
        expr: sort(node_nf_conntrack_entries > node_nf_conntrack_entries_limit * 0.8)
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} has network Connection Tracking System entries of {{$value|printf "%.1f"}} connections.'
      - alert: nodeNetworkErrorRCV
        expr: delta(node_network_receive_errs_total{device!="lo"}[1m]) >= 3
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high error rate in network reception: ({{$value|printf "%.1f"}} packets)'
      - alert: nodeNetworkErrorSND
        expr: delta(node_network_transmit_errs_total{device!="lo"}[1m]) >= 3
        for: 15m
        labels:
          severity: High
        annotations:
          message: '{{$labels.instance}} host has an unusally high error rate in network transmission: ({{$value|printf "%.1f"}} packets)'
      - alert: nodeLimitCPUOvercommit
        expr: (sum(kube_pod_container_resource_limits{resource="cpu"}) by (node) / sum(kube_node_status_capacity_cpu_cores) by (node))*100 >= 100
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Host {{$labels.node}} has an overcommited CPU limit of {{$value|printf "%.1f"}}%'
      - alert: nodeLimitMEMOvercommit
        expr: (sum(kube_pod_container_resource_limits{resource="memory"}) by (node) / sum(kube_node_status_capacity_memory_bytes) by (node))*100 >= 100
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Host {{$labels.node}} has an overcommited memory limit of {{$value|printf "%.1f"}}%'
      - alert: nodeRequestCPUOvercommit
        expr: (sum(kube_pod_container_resource_requests_cpu_cores) by (node) / sum(kube_node_status_capacity_cpu_cores) by (node))*100 >= 100
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'Host {{$labels.node}} has an overcommited CPU request of {{$value}}%'
      - alert: nodeRequestMEMOvercommit
        expr: (sum(kube_pod_container_resource_requests_memory_bytes) by (node) / sum(kube_node_status_capacity_memory_bytes) by (node))*100 >= 100
        for: 15m
        labels:
          severity: Disaster
        annotations:
          message: 'Host {{$labels.node}} has an overcommited memory request of {{$value|printf "%.1f"}}%'
  pod.rules: |
    groups:
    - name: pod.rules
      rules:
      - alert: PodLimit
        expr: kubelet_running_pod_count > 101
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Kubelet {{$labels.instance}} is running {{$value}} pods, close to the limit of 110'
      - alert: contanierStatus
        expr: rate(kube_pod_container_status_restarts_total[1h]) * 3600 > 1
        for: 5s
        labels:
          severity: High
        annotations:
          message: 'Container {{$labels.container_name}} is restarting. {{$labels.namespace}}/{{$labels.pod}} is not ready or CrashLooping'
      - alert: contanierStatus
        expr: rate(kube_pod_container_status_restarts_total[1h]) * 3600 > 5
        for: 5s
        labels:
          severity: Disaster
        annotations:
          message: 'Container {{$labels.container_name}} is restarting. Pod {{$labels.namespace}}/{{$labels.pod}} is not ready or CrashLooping'
      - alert: podStatus
        expr: sum by (namespace, pod) (kube_pod_status_phase{phase!~"Running|Succeeded"}) > 0
        for: 1m
        labels:
          severity: Disaster
        annotations:
          message: '{{$labels.namespace}}/{{$labels.pod}} is not ready. Status{{$labels.phase}}'
      - alert: jobFailed
        expr: kube_job_status_failed > 0
        for: 15m
        labels:
          severity: High
        annotations:
          message: 'Job {{$labels.namespace}}/{{$labels.job_name}} failed to complete.'
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: prometheus-rules
  namespace: monitoring
